{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First AI model inspired by:\n",
    "- https://www.youtube.com/watch?v=jR0phoeXjrc&ab_channel=VenelinValkov\n",
    "- https://www.youtube.com/watch?v=PCgrgHgy26c&ab_channel=VenelinValkov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = \"2023_04_14\"\n",
    "DATA_FOLDER = os.path.join(\"../data/android_app/\", DATE)\n",
    "\n",
    "DATA_FILES = [file for file in os.listdir(DATA_FOLDER) if os.path.isfile(os.path.join(DATA_FOLDER, file)) and file.endswith(\".txt\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(os.path.join(DATA_FOLDER, DATE + \".csv\"))\n",
    "y = pd.read_csv(os.path.join(DATA_FOLDER,DATE + \".labels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>index</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATA43.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220267</td>\n",
       "      <td>0.172383</td>\n",
       "      <td>9.959879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA43.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181959</td>\n",
       "      <td>0.105345</td>\n",
       "      <td>10.046070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATA43.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.325611</td>\n",
       "      <td>0.220267</td>\n",
       "      <td>9.768343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA43.txt</td>\n",
       "      <td>3</td>\n",
       "      <td>0.277727</td>\n",
       "      <td>0.105345</td>\n",
       "      <td>9.787497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA43.txt</td>\n",
       "      <td>4</td>\n",
       "      <td>0.287304</td>\n",
       "      <td>0.220267</td>\n",
       "      <td>9.950302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file  index        ax        ay         az\n",
       "0  DATA43.txt      0  0.220267  0.172383   9.959879\n",
       "1  DATA43.txt      1  0.181959  0.105345  10.046070\n",
       "2  DATA43.txt      2  0.325611  0.220267   9.768343\n",
       "3  DATA43.txt      3  0.277727  0.105345   9.787497\n",
       "4  DATA43.txt      4  0.287304  0.220267   9.950302"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATA1.txt</td>\n",
       "      <td>speed_bump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DATA2.txt</td>\n",
       "      <td>speed_bump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATA3.txt</td>\n",
       "      <td>speed_bump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATA4.txt</td>\n",
       "      <td>speed_bump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA5.txt</td>\n",
       "      <td>speed_bump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file       label\n",
       "0  DATA1.txt  speed_bump\n",
       "1  DATA2.txt  speed_bump\n",
       "2  DATA3.txt  speed_bump\n",
       "3  DATA4.txt  speed_bump\n",
       "4  DATA5.txt  speed_bump"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "y.label.value_counts().plot(kind=\"bar\")\n",
    "# plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert file to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileToInt(file):\n",
    "    file = file[4:] # Remove \"DATA\"\n",
    "    file = file[:len(file)-4] # Remove \".txt\"\n",
    "    return int(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"file\"] = X[\"file\"].apply(fileToInt)\n",
    "y[\"file\"] = y[\"file\"].apply(fileToInt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(y.label)\n",
    "y[\"encoded_label\"] = encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bumpy_tiles', 'crack', 'hole', 'hole+crack+bumps', 'speed_bump',\n",
       "       'speed_bump+hole', 'tree_bumps'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>speed_bump</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>speed_bump</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>speed_bump</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>speed_bump</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>speed_bump</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file       label  encoded_label\n",
       "0     1  speed_bump              4\n",
       "1     2  speed_bump              4\n",
       "2     3  speed_bump              4\n",
       "3     4  speed_bump              4\n",
       "4     5  speed_bump              4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71    9488\n",
       "72    7856\n",
       "74    7855\n",
       "76    7826\n",
       "67    7815\n",
       "      ... \n",
       "14    1436\n",
       "24    1427\n",
       "22    1395\n",
       "16    1292\n",
       "20    1288\n",
       "Name: file, Length: 82, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.file.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = max(X.file.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "sequences_encoded_labels = []\n",
    "\n",
    "for file, group in X.groupby(\"file\"):\n",
    "    sequence_features = group[FEATURE_COLUMNS]\n",
    "    encoded_label = y[y.file == file].iloc[0].encoded_label\n",
    "    \n",
    "    last_index = sequence_features.index[len(sequence_features)-1]\n",
    "\n",
    "    # Sequences must have the same length -> add padding...\n",
    "    if len(sequence_features) < sequence_length:\n",
    "        padding_length = sequence_length - len(sequence_features)\n",
    "        new_rows = pd.DataFrame({\"file\": [file for i in range(padding_length)], \"index\": [i+last_index+1 for i in range(padding_length)], \"ax\": [0 for i in range(padding_length)], \"ay\": [0 for i in range(padding_length)], \"az\": [0 for i in range(padding_length)]}, index=[i+last_index+1 for i in range(padding_length)])\n",
    "        sequence_features = pd.concat([sequence_features,new_rows]).reset_index(drop=True)\n",
    "\n",
    "    sequences.append((sequence_features, encoded_label))\n",
    "    sequences_encoded_labels.append(encoded_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      file   index        ax        ay         az\n",
       " 0        1       0  0.076614 -0.938527  10.611102\n",
       " 1        1       1 -0.114922  0.478840  11.166556\n",
       " 2        1       2 -0.258574  0.794875   9.988609\n",
       " 3        1       3  0.325611 -0.555455  10.046070\n",
       " 4        1       4  0.488417  0.181959   9.548077\n",
       " ...    ...     ...       ...       ...        ...\n",
       " 9483     1  222351  0.000000  0.000000   0.000000\n",
       " 9484     1  222352  0.000000  0.000000   0.000000\n",
       " 9485     1  222353  0.000000  0.000000   0.000000\n",
       " 9486     1  222354  0.000000  0.000000   0.000000\n",
       " 9487     1  222355  0.000000  0.000000   0.000000\n",
       " \n",
       " [9488 rows x 5 columns],\n",
       " 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train/Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequences: 65 | Test sequences: 17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sequences, test_sequences = train_test_split(sequences, test_size=0.2,shuffle=True, random_state=66, stratify=sequences_encoded_labels)\n",
    "print(f\"Train sequences: {len(train_sequences)} | Test sequences: {len(test_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ObstacleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence, encoded_label = self.sequences[idx]\n",
    "        return dict(\n",
    "            sequence=torch.Tensor(sequence.to_numpy()),\n",
    "            encoded_label=torch.tensor(encoded_label).long()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "class ObstacleDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, train_sequences, test_sequences, batch_size):\n",
    "        super().__init__()\n",
    "        self.train_sequences = train_sequences\n",
    "        self.test_sequences = test_sequences\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = ObstacleDataset(self.train_sequences)\n",
    "        self.test_dataset = ObstacleDataset(self.test_sequences)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=cpu_count()\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=cpu_count()\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=cpu_count()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data_module = ObstacleDataModule(train_sequences, test_sequences, BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class SequenceModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features, n_classes, n_hidden=256, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=n_hidden,\n",
    "            num_layers=n_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.785\n",
    "        )\n",
    "        self.classifier = nn.Linear(n_hidden, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.lstm.flatten_parameters()\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        out = hidden[-1]\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "class ObstaclePredictor(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, n_features: int, n_classes: int):\n",
    "        super().__init__()\n",
    "        self.model = SequenceModel(n_features, n_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.accuracy = MulticlassAccuracy(num_classes=len(label_encoder.classes_), average=\"weighted\", top_k=1)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        output = self.model(x)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels)\n",
    "        return loss, output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        encoded_labels = batch[\"encoded_label\"]\n",
    "        loss, outputs = self.forward(sequences, encoded_labels)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        step_accuracy = self.accuracy(predictions, encoded_labels)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"train_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\"loss\": loss, \"accuracy\": step_accuracy}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        encoded_labels = batch[\"encoded_label\"]\n",
    "        loss, outputs = self.forward(sequences, encoded_labels)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        step_accuracy = self.accuracy(predictions, encoded_labels)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"val_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\"loss\": loss, \"accuracy\": step_accuracy}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        encoded_labels = batch[\"encoded_label\"]\n",
    "        loss, outputs = self.forward(sequences, encoded_labels)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        step_accuracy = self.accuracy(predictions, encoded_labels)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"test_accuracy\", step_accuracy, prog_bar=True, logger=True)\n",
    "\n",
    "        return {\"loss\": loss, \"accuracy\": step_accuracy}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ObstaclePredictor(\n",
    "    n_features=len(FEATURE_COLUMNS),\n",
    "    n_classes=len(label_encoder.classes_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c82d98b3e573162e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c82d98b3e573162e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"surface\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    # checkpoint_callback=checkpoint_callback,\n",
    "    max_epochs=N_EPOCHS,\n",
    "    # gpus=1,\n",
    "    # progress_bar_refresh_rate=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | SequenceModel      | 1.3 M \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "2 | accuracy  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.295     Total estimated model params size (MB)\n",
      "2023-05-01 14:51:18.575853: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 14:51:18.827378: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-01 14:51:19.962001: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-01 14:51:19.962122: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-01 14:51:19.962134: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f945b9c63e14a8689a748db914b3622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "update() got an unexpected keyword argument 'task'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/fabien/TPS/2A/ProjetIngenieur/ai/LSTM.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/fabien/TPS/2A/ProjetIngenieur/ai/LSTM.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, data_module)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:520\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    518\u001b[0m model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    519\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 520\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    521\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    522\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     43\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:559\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    550\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    553\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    554\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    555\u001b[0m     ckpt_path,\n\u001b[1;32m    556\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    558\u001b[0m )\n\u001b[0;32m--> 559\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    561\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    562\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:935\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    932\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 935\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    937\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    940\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:976\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[1;32m    975\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m--> 976\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m    977\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[1;32m    978\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1005\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1002\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1004\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1005\u001b[0m val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1007\u001b[0m call\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1009\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:177\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     context_manager \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mno_grad\n\u001b[1;32m    176\u001b[0m \u001b[39mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 177\u001b[0m     \u001b[39mreturn\u001b[39;00m loop_run(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:115\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m     previous_dataloader_idx \u001b[39m=\u001b[39m dataloader_idx\n\u001b[1;32m    114\u001b[0m     \u001b[39m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(batch, batch_idx, dataloader_idx)\n\u001b[1;32m    116\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[39m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:375\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    374\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 375\u001b[0m output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, hook_name, \u001b[39m*\u001b[39;49mstep_kwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    377\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    379\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_test_batch_end\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mon_validation_batch_end\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:288\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 288\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    290\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    291\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:378\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[1;32m    377\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[0;32m--> 378\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/home/fabien/TPS/2A/ProjetIngenieur/ai/LSTM.ipynb Cell 35\u001b[0m in \u001b[0;36mObstaclePredictor.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fabien/TPS/2A/ProjetIngenieur/ai/LSTM.ipynb#X43sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m loss, outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(sequences, encoded_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fabien/TPS/2A/ProjetIngenieur/ai/LSTM.ipynb#X43sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fabien/TPS/2A/ProjetIngenieur/ai/LSTM.ipynb#X43sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m step_accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccuracy(predictions, encoded_labels, task\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmulticlass\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fabien/TPS/2A/ProjetIngenieur/ai/LSTM.ipynb#X43sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, loss, prog_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, logger\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fabien/TPS/2A/ProjetIngenieur/ai/LSTM.ipynb#X43sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m\"\u001b[39m, step_accuracy, prog_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, logger\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/metric.py:236\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_full_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    235\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_reduce_state_update(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    238\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/metric.py:302\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[39m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    303\u001b[0m batch_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute()\n\u001b[1;32m    305\u001b[0m \u001b[39m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/metric.py:390\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad):\n\u001b[1;32m    389\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         update(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    391\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    392\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n",
      "\u001b[0;31mTypeError\u001b[0m: update() got an unexpected keyword argument 'task'"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
